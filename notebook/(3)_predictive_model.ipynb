{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(3)_predictive_model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYC9eHdOc6yi"
      },
      "source": [
        "<strong>Date :</strong> Créé le 07 Avril 2021| Mis à jour le 11 Avril 2021 </strong>\n",
        "\n",
        "<strong>Compétition Kaggle - Team Théo\n",
        "    \n",
        "@auteur : </strong>Théo SACCAREAU & Théo VEDIS\n",
        "\n",
        "<strong>(3)_predictive_model\n",
        "      \n",
        "Description :</strong> Après avoir mis au point une trentaine de features, notre objectif est de mettre au point un modèle de prédiction des scores. \n",
        "\n",
        "Temps d'exécution du Notebook : environ  5min (entre 1 et 2 heures si l'optimisation des paramètres est effectuée)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imAEsGzZGyz-"
      },
      "source": [
        "# Importation des librairies\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcvnUgP4Gyz4"
      },
      "source": [
        "# Librairies usuelles \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Libraries pour les modèles de prédiction \n",
        "# 1ere partie - Classification \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# 2e partie - Régression \n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Validation croisée \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "# Optimisaton des hyper-paramètres \n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUNxsXdGMpP"
      },
      "source": [
        "# Chemin "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY896iIwGy0G"
      },
      "source": [
        "# Chemin relatif vers le dossier \"data\" (inutile de le changer).\n",
        "pathFile = \"../data/\" "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaPBGrY2AciM"
      },
      "source": [
        "# Chargement des données d'entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwAmPvxAI3w"
      },
      "source": [
        "# Ouverture du fichier contenant l'ensemble des features \n",
        "# Temps exécution : 2min\n",
        "with open( pathFile + 'df_features.json') as json_data:\n",
        "    data_dict = json.load(json_data)\n",
        "\n",
        "# On transforme le dictionnaire en DataFrame \n",
        "# Temps exécution : 1min\n",
        "df = pd.DataFrame(data_dict)\n",
        "\n",
        "# On libère de la RAM en supprimant la variable data_dict qui ne nous servira plus\n",
        "del data_dict "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8BEAdJQ1ICU"
      },
      "source": [
        "# On conserve le nom des commentaires dans une variable (pour la soumission) et\n",
        "# on la supprime du dataframe (ce n'est pas une feature)\n",
        "name = df['name']\n",
        "df = df.drop(columns=['name'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN3_Dqh96m-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "4ada1e24-7409-4695-928e-ea5d206c3a19"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ups</th>\n",
              "      <th>is_parent_comment</th>\n",
              "      <th>is_author_deleted</th>\n",
              "      <th>is_body_deleted</th>\n",
              "      <th>bot_comment</th>\n",
              "      <th>length_comment_chars_before_NLP</th>\n",
              "      <th>length_comment_chars_after_NLP</th>\n",
              "      <th>length_comment_words</th>\n",
              "      <th>nb_stopwords</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_child</th>\n",
              "      <th>depth</th>\n",
              "      <th>nb_direct_resp</th>\n",
              "      <th>nb_total_resp</th>\n",
              "      <th>author_centrality_degree</th>\n",
              "      <th>author_centrality_ev</th>\n",
              "      <th>author_prestige_degree</th>\n",
              "      <th>hour</th>\n",
              "      <th>resp_time_parent</th>\n",
              "      <th>resp_time_topic</th>\n",
              "      <th>score_parent</th>\n",
              "      <th>score_topic</th>\n",
              "      <th>nb_comments_parent</th>\n",
              "      <th>nb_comments_topic</th>\n",
              "      <th>ratio_topic</th>\n",
              "      <th>author_mean_score</th>\n",
              "      <th>isSameAuthor</th>\n",
              "      <th>year_creation_author</th>\n",
              "      <th>has_verified_email</th>\n",
              "      <th>comment_karma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>14</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>1.312352e-03</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22894</td>\n",
              "      <td>NaN</td>\n",
              "      <td>817</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>0.86</td>\n",
              "      <td>18.702703</td>\n",
              "      <td>False</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>True</td>\n",
              "      <td>181760.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>2.167334e-19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>night</td>\n",
              "      <td>13205.0</td>\n",
              "      <td>13205</td>\n",
              "      <td>10800.0</td>\n",
              "      <td>10800</td>\n",
              "      <td>1443</td>\n",
              "      <td>1443</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>False</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>True</td>\n",
              "      <td>23937.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>neu</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>1.712427e-03</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20339</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3268</td>\n",
              "      <td>5</td>\n",
              "      <td>1610</td>\n",
              "      <td>0.82</td>\n",
              "      <td>3.105263</td>\n",
              "      <td>False</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>True</td>\n",
              "      <td>125197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.167334e-19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>109679</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13643</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>0.82</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>False</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>True</td>\n",
              "      <td>7663.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>101.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>241</td>\n",
              "      <td>164</td>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>pos</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>5.092290e-05</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>night</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>817</td>\n",
              "      <td>2</td>\n",
              "      <td>322</td>\n",
              "      <td>0.86</td>\n",
              "      <td>51.500000</td>\n",
              "      <td>False</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>True</td>\n",
              "      <td>5344.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ups  is_parent_comment  ...  has_verified_email  comment_karma\n",
              "0    3.0                  1  ...                True       181760.0\n",
              "1    3.0                  0  ...                True        23937.0\n",
              "2    5.0                  1  ...                True       125197.0\n",
              "3    1.0                  1  ...                True         7663.0\n",
              "4  101.0                  1  ...                True         5344.0\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCKB7OJ4ZOwY"
      },
      "source": [
        "# Ultime nettoyage\n",
        "Avant que notre DataFrame contenant les features soient totalement prêt, il reste deux étapes à effectuer : \n",
        "- la correction des valeurs nulles pour certaines features (certains algorithmes de Machine Learning ne savent pas comment traiter ces valeurs et échoueront)\n",
        "- la conversion des features qualitative. En effet, la bibliothèque \"Scklearn\" ne prend pas en charge les variables nominales. Il faut donc les transformer en variables quantitatives binaires (si deux modalités) ou n-aires grâce à la commande \"get_dummies\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wurra7x6nA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8d761b-1d11-48a8-b559-e532324dd8f7"
      },
      "source": [
        "# On vérifie quelles variables ont des valeurs nulles.\n",
        "df.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ups                                1016458\n",
              "is_parent_comment                        0\n",
              "is_author_deleted                        0\n",
              "is_body_deleted                          0\n",
              "bot_comment                              0\n",
              "length_comment_chars_before_NLP          0\n",
              "length_comment_chars_after_NLP           0\n",
              "length_comment_words                     0\n",
              "nb_stopwords                             0\n",
              "sentiment                                0\n",
              "sentiment_child                          0\n",
              "depth                                    0\n",
              "nb_direct_resp                           0\n",
              "nb_total_resp                            0\n",
              "author_centrality_degree                 0\n",
              "author_centrality_ev                     0\n",
              "author_prestige_degree                   0\n",
              "hour                                     0\n",
              "resp_time_parent                     22566\n",
              "resp_time_topic                          0\n",
              "score_parent                        605525\n",
              "score_topic                              0\n",
              "nb_comments_parent                       0\n",
              "nb_comments_topic                        0\n",
              "ratio_topic                              0\n",
              "author_mean_score                   183489\n",
              "isSameAuthor                             0\n",
              "year_creation_author                999517\n",
              "has_verified_email                  999517\n",
              "comment_karma                       999517\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN9qfvOvbXef"
      },
      "source": [
        "Il y a donc 6 variables qui contiennent des valeurs nulles (`ups` exclue). Il y a plusieurs façons de procéder pour remplacer ces valeurs nulles : remplacer par 0, remplacer par la médiane, remplacer par la moyenne, remplacer par la valeur la plus fréquente etc. <br>\n",
        "- Pour `resp_time_parent`, nous avons fait le choix de remplacer les valeurs manquantes par la moyenne. C'est la solution qui nous paraissait la plus naturelle car elle permet de ne pas discriminer positivement ou négativement les commentaires n'ayant pas ce type d'informations.  \n",
        "- Pour `score_parent`, nous n'avons pas choisi d'utiliser la moyenne tout simplement parce une très grande majorité des scores de parents est de 1 mais la moyenne vaut plus de 1000 (car il y a quelques rares commentaires parents qui ont un score extrêment élevé). Ainsi, nous estimons qu'il est mieux de donner comme score le score le plus fréquent (1) plutôt que la moyenne qui est dopée par des commentaires extrêmes (1073). \n",
        "- Pour `author_mean_score` et `comment_karma`, même raisonnement que pour `score_parent`. \n",
        "- Enfin, pour `year_creation_author` et `has_verified_email`, ce sont deux variables avec modalités, il faut donc clairement utiliser la valeur la plus fréquente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6cKSB-76nDf"
      },
      "source": [
        "# On calcule les valeurs de remplacement\n",
        "mean_resp_time = df['resp_time_parent'].mean()\n",
        "freq_score_parent = df['score_parent'].value_counts().index[0]\n",
        "freq_score_author = df['author_mean_score'].value_counts().index[0]\n",
        "freq_karma = df['comment_karma'].value_counts().index[0]\n",
        "freq_year = df['year_creation_author'].value_counts().index[0]\n",
        "freq_email = df['has_verified_email'].value_counts().index[0]\n",
        "\n",
        "# Puis on remplace les valeurs nulles par les valeurs calculées au-dessus\n",
        "df['resp_time_parent'] = df['resp_time_parent'].fillna(mean_resp_time)\n",
        "df['score_parent'] = df['score_parent'].fillna(freq_score_parent)\n",
        "df['author_mean_score'] = df['author_mean_score'].fillna(freq_score_author)\n",
        "df['comment_karma'] = df['comment_karma'].fillna(freq_karma)\n",
        "df['year_creation_author'] = df['year_creation_author'].fillna(freq_year)\n",
        "df['has_verified_email'] = df['has_verified_email'].fillna(freq_email)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q4wWI9DfRIc",
        "outputId": "6dcf11ca-5b5a-49a2-dc5c-f5f713f4873b"
      },
      "source": [
        "# Vérification\n",
        "df.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ups                                1016458\n",
              "is_parent_comment                        0\n",
              "is_author_deleted                        0\n",
              "is_body_deleted                          0\n",
              "bot_comment                              0\n",
              "length_comment_chars_before_NLP          0\n",
              "length_comment_chars_after_NLP           0\n",
              "length_comment_words                     0\n",
              "nb_stopwords                             0\n",
              "sentiment                                0\n",
              "sentiment_child                          0\n",
              "depth                                    0\n",
              "nb_direct_resp                           0\n",
              "nb_total_resp                            0\n",
              "author_centrality_degree                 0\n",
              "author_centrality_ev                     0\n",
              "author_prestige_degree                   0\n",
              "hour                                     0\n",
              "resp_time_parent                         0\n",
              "resp_time_topic                          0\n",
              "score_parent                             0\n",
              "score_topic                              0\n",
              "nb_comments_parent                       0\n",
              "nb_comments_topic                        0\n",
              "ratio_topic                              0\n",
              "author_mean_score                        0\n",
              "isSameAuthor                             0\n",
              "year_creation_author                     0\n",
              "has_verified_email                       0\n",
              "comment_karma                            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht4ScZSjfsy1"
      },
      "source": [
        "Il n'y a plus de variables avec des valeurs nulles (hormis `ups`). \n",
        "\n",
        "Passons à la vérification des types de données. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZuSKH0YoE_b",
        "outputId": "a5c548a4-9508-4c93-9639-6173a8a72eb4"
      },
      "source": [
        "# Informations sur les types des variables\n",
        "print(df.info())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4234970 entries, 0 to 4234969\n",
            "Data columns (total 30 columns):\n",
            " #   Column                           Dtype  \n",
            "---  ------                           -----  \n",
            " 0   ups                              float64\n",
            " 1   is_parent_comment                int64  \n",
            " 2   is_author_deleted                int64  \n",
            " 3   is_body_deleted                  int64  \n",
            " 4   bot_comment                      int64  \n",
            " 5   length_comment_chars_before_NLP  int64  \n",
            " 6   length_comment_chars_after_NLP   int64  \n",
            " 7   length_comment_words             int64  \n",
            " 8   nb_stopwords                     int64  \n",
            " 9   sentiment                        object \n",
            " 10  sentiment_child                  int64  \n",
            " 11  depth                            int64  \n",
            " 12  nb_direct_resp                   int64  \n",
            " 13  nb_total_resp                    int64  \n",
            " 14  author_centrality_degree         float64\n",
            " 15  author_centrality_ev             float64\n",
            " 16  author_prestige_degree           float64\n",
            " 17  hour                             object \n",
            " 18  resp_time_parent                 float64\n",
            " 19  resp_time_topic                  int64  \n",
            " 20  score_parent                     float64\n",
            " 21  score_topic                      int64  \n",
            " 22  nb_comments_parent               int64  \n",
            " 23  nb_comments_topic                int64  \n",
            " 24  ratio_topic                      float64\n",
            " 25  author_mean_score                float64\n",
            " 26  isSameAuthor                     bool   \n",
            " 27  year_creation_author             float64\n",
            " 28  has_verified_email               bool   \n",
            " 29  comment_karma                    float64\n",
            "dtypes: bool(2), float64(10), int64(16), object(2)\n",
            "memory usage: 945.1+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOcgYWEYoScO"
      },
      "source": [
        "Quaatre variables ne sont pas de types quantitatives : `sentiment`, `hour` (de type `str`), `has_verified_email` et `isSameAuthor` (de type `boolean`). <br>  Pour ces deux dernières il suffit de remplacer `True` par 1 et `False` par 0. <br>\n",
        "Pour les variables nominales, nous utiliserons la fonction `get_dummies`.  Cette commande élimine les variables nominales en créant de nouvelles colonnes. Ces nouvelles colonnes portent le nom de la modalité de la variable nominale (exemple : 'sentiment_neg' pour sentiment négatif) et leur valeur vaut 0 (le commentaire n'avait pas cette modalité) ou 1 (le commentaire avait cette modalité). Ainsi de suite pour les 4 autres modalités. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRi2OZoio95l"
      },
      "source": [
        "# Transformation des variables de type 'booléen' en variables quantitatives\n",
        "df['isSameAuthor'] = df['isSameAuthor'].apply(lambda x : 1 if x else 0)\n",
        "df['has_verified_email'] = df['has_verified_email'].apply(lambda x : 1 if x else 0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWXY6TX5o-DT"
      },
      "source": [
        "# Transformation des variables nominales en variables quantitatives\n",
        "df = pd.get_dummies(df)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5L30vxLpSYV",
        "outputId": "11aa83bc-da82-4efc-be62-edb062ada7ba"
      },
      "source": [
        "# Vérification \n",
        "print(df.info())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4234970 entries, 0 to 4234969\n",
            "Data columns (total 35 columns):\n",
            " #   Column                           Dtype  \n",
            "---  ------                           -----  \n",
            " 0   ups                              float64\n",
            " 1   is_parent_comment                int64  \n",
            " 2   is_author_deleted                int64  \n",
            " 3   is_body_deleted                  int64  \n",
            " 4   bot_comment                      int64  \n",
            " 5   length_comment_chars_before_NLP  int64  \n",
            " 6   length_comment_chars_after_NLP   int64  \n",
            " 7   length_comment_words             int64  \n",
            " 8   nb_stopwords                     int64  \n",
            " 9   sentiment_child                  int64  \n",
            " 10  depth                            int64  \n",
            " 11  nb_direct_resp                   int64  \n",
            " 12  nb_total_resp                    int64  \n",
            " 13  author_centrality_degree         float64\n",
            " 14  author_centrality_ev             float64\n",
            " 15  author_prestige_degree           float64\n",
            " 16  resp_time_parent                 float64\n",
            " 17  resp_time_topic                  int64  \n",
            " 18  score_parent                     float64\n",
            " 19  score_topic                      int64  \n",
            " 20  nb_comments_parent               int64  \n",
            " 21  nb_comments_topic                int64  \n",
            " 22  ratio_topic                      float64\n",
            " 23  author_mean_score                float64\n",
            " 24  isSameAuthor                     int64  \n",
            " 25  year_creation_author             float64\n",
            " 26  has_verified_email               int64  \n",
            " 27  comment_karma                    float64\n",
            " 28  sentiment_neg                    uint8  \n",
            " 29  sentiment_neu                    uint8  \n",
            " 30  sentiment_pos                    uint8  \n",
            " 31  hour_afternoon                   uint8  \n",
            " 32  hour_evening                     uint8  \n",
            " 33  hour_morning                     uint8  \n",
            " 34  hour_night                       uint8  \n",
            "dtypes: float64(10), int64(18), uint8(7)\n",
            "memory usage: 965.3+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSSBDs6vxkJn"
      },
      "source": [
        "Enfin, on convertit les colonnes qui étaient en `float` (à cause des `np.nan`) en `int`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNv9AHNJxjgI",
        "outputId": "d2f35a01-5eae-4317-f781-e11f27458894"
      },
      "source": [
        "# Liste des colonnes à convertir en int\n",
        "columns_to_int = ['resp_time_parent', 'score_parent', 'comment_karma', \n",
        "                  'year_creation_author', 'has_verified_email'] \n",
        "                  # Pas de author_mean_score car les valeurs peuvent être décimales\n",
        "\n",
        "for col in tqdm(columns_to_int) : \n",
        "    df[col] = df[col].apply(lambda x : int(x))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:10<00:00,  2.08s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqKZZPjrp6-0",
        "outputId": "ad61811b-e5d4-44c0-f9de-a201494ff8fe"
      },
      "source": [
        "# Dernière vérification \n",
        "print(df.info())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4234970 entries, 0 to 4234969\n",
            "Data columns (total 35 columns):\n",
            " #   Column                           Dtype  \n",
            "---  ------                           -----  \n",
            " 0   ups                              float64\n",
            " 1   is_parent_comment                int64  \n",
            " 2   is_author_deleted                int64  \n",
            " 3   is_body_deleted                  int64  \n",
            " 4   bot_comment                      int64  \n",
            " 5   length_comment_chars_before_NLP  int64  \n",
            " 6   length_comment_chars_after_NLP   int64  \n",
            " 7   length_comment_words             int64  \n",
            " 8   nb_stopwords                     int64  \n",
            " 9   sentiment_child                  int64  \n",
            " 10  depth                            int64  \n",
            " 11  nb_direct_resp                   int64  \n",
            " 12  nb_total_resp                    int64  \n",
            " 13  author_centrality_degree         float64\n",
            " 14  author_centrality_ev             float64\n",
            " 15  author_prestige_degree           float64\n",
            " 16  resp_time_parent                 int64  \n",
            " 17  resp_time_topic                  int64  \n",
            " 18  score_parent                     int64  \n",
            " 19  score_topic                      int64  \n",
            " 20  nb_comments_parent               int64  \n",
            " 21  nb_comments_topic                int64  \n",
            " 22  ratio_topic                      float64\n",
            " 23  author_mean_score                float64\n",
            " 24  isSameAuthor                     int64  \n",
            " 25  year_creation_author             int64  \n",
            " 26  has_verified_email               int64  \n",
            " 27  comment_karma                    int64  \n",
            " 28  sentiment_neg                    uint8  \n",
            " 29  sentiment_neu                    uint8  \n",
            " 30  sentiment_pos                    uint8  \n",
            " 31  hour_afternoon                   uint8  \n",
            " 32  hour_evening                     uint8  \n",
            " 33  hour_morning                     uint8  \n",
            " 34  hour_night                       uint8  \n",
            "dtypes: float64(6), int64(22), uint8(7)\n",
            "memory usage: 965.3+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZWzOCQw3SnV"
      },
      "source": [
        "Remarque : Le type `int64` correspond à des entiers signés sur 64 bits et le type `uint8`à des entiers non-signés sur 8 bits. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibQfCNGYqwl"
      },
      "source": [
        "# Séparation train-test\n",
        "Désormais que notre DataFrame est prêt à l'emploi, on le sépare en deux : une partie sera dédié à l'apprentissage ('train') et l'autre à l'évaluation des prédictions ('test'). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD9rCJ9zrr4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d682aeac-9127-4408-c804-08601d2e05d9"
      },
      "source": [
        "# Comme imposé par l'énoncé, le découpage se fait selon les valeurs de 'ups'.\n",
        "df_train = df.loc[np.isnan(df['ups']) == False]\n",
        "df_test = df.loc[np.isnan(df['ups'])]\n",
        "\n",
        "# On vérifie que le découpage ne laissent aucun commentaire sur le côté\n",
        "print(df.shape[0] == (df_train.shape[0] + df_test.shape[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPVm_gdRsHbx",
        "outputId": "635a912b-1aaf-44dd-8653-eca80e0b19e2"
      },
      "source": [
        "print(\"TRAIN DATA: \\nNombre de lignes: %i (%.f%%) \"\\\n",
        "      %(df_train.shape[0], df_train.shape[0]/df.shape[0]*100))\n",
        "\n",
        "print(\"\\nTEST DATA: \\nNombre de lignes: %i (%.f%%) \"\\\n",
        "      %(df_test.shape[0], df_test.shape[0]/df.shape[0]*100))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN DATA: \n",
            "Nombre de lignes: 3218512 (76%) \n",
            "\n",
            "TEST DATA: \n",
            "Nombre de lignes: 1016458 (24%) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfxL-J9Vh43t"
      },
      "source": [
        "L'échantillon de train représente plus de 75% des données. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PkRFjw9h5if"
      },
      "source": [
        "Comme on va réaliser un apprentissage supervisé, on doit séparer l'ensemble 'train' en deux parties : une partie contenant les features (Xtrain) et l'autre contenant la variable à prédire (Ytrain, ici le score). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30zAUDbtrgyb"
      },
      "source": [
        "# Séparation features / variable à prédire \n",
        "\n",
        "Xtrain = df_train.iloc[:, 1:]\n",
        "Ytrain = pd.Series(df_train.iloc[:, 0], dtype=int)\n",
        "Xtest = df_test.iloc[:, 1:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGxH7ZiMras3"
      },
      "source": [
        "# Modèle de prédiction \n",
        "Tout est désormais prêt pour qu'on puisse mettre en place un modèle de prédiction des scores de commentaires. <br>\n",
        "Pour commencer, regardons la répartition des scores sur l'échnatillon d'apprentissage. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BapJaa9fkDbX",
        "outputId": "7db8282c-d36d-4faa-f2ea-04acd78331f3"
      },
      "source": [
        "pd.Series(Ytrain).value_counts()[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    1676837\n",
              " 2     575082\n",
              " 3     219060\n",
              " 0     153372\n",
              " 4      75130\n",
              " 5      66586\n",
              " 6      47904\n",
              "-1      38365\n",
              " 7      34214\n",
              " 8      25921\n",
              "Name: ups, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcWDve3vxsj"
      },
      "source": [
        "On constate que plus de 1.67 millions de commentaires ont pour score 1. Cela représente (52% des données d'entrainement).\n",
        "\n",
        "En faisant cette constatation, nous avons décidé de réaliser un premier modèle de classification avant de créer un modèle de régression. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFt9_g6rYbNn"
      },
      "source": [
        "## (1) Modèle(s) de classification \n",
        "L'objectif de cette première étape est d'essayer de séparer nos commentaires en deux : d'un côté les commentaires avec un score de 1, de l'autre le reste des commentaires. Cela permettrait d'avoir deux groupes plus ou moins de même taille mais surtout nous pensons que le modèle de regréssion appliqué sur le deuxième groupe aura plus de faciliter à prédire car il sera moins \"géné\" par la forte porportion de 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrhMXaeg0PeZ"
      },
      "source": [
        "### 1-1 Séparation des données train \n",
        "La première étape est de constitué une nouvelle liste de Ytrain constituée uniquement de 1 (score égal à 1) ou de 0 (score différent de 1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii0TfQP40T3m"
      },
      "source": [
        "def partition(y):\n",
        "    \"\"\"\n",
        "    Fonction qui permet de transformer Ytrain (variable continue) en variable \n",
        "    binaire composée de 0 ou de 1. \n",
        "\n",
        "    Paramètre : \n",
        "        - y (int) : score du commentaire initial.\n",
        "    \n",
        "    Sortie : \n",
        "        - y (int) : deux valeurs possibles : 1 si le paramètre d'entrée \n",
        "        valait 1, 0 sinon. \n",
        "    \"\"\"\n",
        "\n",
        "    if (y == 1):\n",
        "        y = 1\n",
        "    \n",
        "    else :\n",
        "        y = 0\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6m32u9v0-yW",
        "outputId": "46aa5aa2-c6cd-43bd-d512-e4873bfb98a4"
      },
      "source": [
        "Ytrain_classif = [partition(y) for y in Ytrain]\n",
        "pd.Series(Ytrain_classif).value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1676837\n",
              "0    1541675\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8oqhldq1Mh-"
      },
      "source": [
        "Comme évoqué au-dessus, le fait d'appliquer cette classification sur Ytrain, permet d'obtenir (en théorie), deux groupes homogènes. \n",
        "\n",
        "L'objectif est désormais de trouver un modèle de classification qui permettent de séparer les données de test de cette façon. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grYF-_Ne0CyN"
      },
      "source": [
        "### 1-2 Choix du modèle de classification \n",
        "La première étape est bien évidemment de choisir le meilleur modèle de classification. \n",
        "\n",
        "Pour cela, nous avons pré-sélectionné 4 modèles de classification : `KNeighbors`, `LightGBM`, `DecisionTree` et `LogisticRegression`. Cette sélection s'est fait à partir de nos expériences passées et nous avaons fait en sorte d'utiliser plusieurs types d'algorithmes : linéaire (régression logistique), descente de gradient (LightGBM), plus proches voisins (KNeighbors) et arbre de décision (DecisionTree). \n",
        "\n",
        "Pour pouvoir sélectionner le meilleur modèle, nous devons réaliser une validation croisée sur l'échantion d'apprentissage. Il existe plusieurs types de validation croisée, le plus courant est la méthode \"k-folds\". Elle consiste à diviser l'échantillon d'apprentissage 'train' en k sous-échantillons, puis à sélectionner un des k sous-échantillions comme l'ensemble de test et les k-1 autres sous-échantillons constituent l'ensemble d'apprentissage. Ensuite, le score de performance (taux de prédiction dans notre cas car nous utilisons des classifieur) est calculé. Cette opération se répète ensuite en sélectionnant un autre sous-échantillon de test parmi les k-1 restant. L'opération se répète ainsi k fois pour qu'en fin de compte chaque sous-échantillon ait été utilisé exactement une fois comme ensemble de test. La mesure de performance rapportée par la validation croisée \"k-folds\" est alors la moyenne des valeurs calculée dans la boucle. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Yr5P3kz7gi"
      },
      "source": [
        "# 4 modèles qu'on souhaite comparer\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "reglog = LogisticRegression(random_state=1234, max_iter=500)\n",
        "lgbm = LGBMClassifier(random_state=1234)\n",
        "tree = tree.DecisionTreeClassifier(random_state=1234)\n",
        "\n",
        "# Liste qui contiendra la liste des moyennes des taux de prédictions à chaque \n",
        "# itération pour chaque modèle. \n",
        "scores = []\n",
        "\n",
        "# Pour chaque modèle on réalise une validation croisée.\n",
        "for model in tqdm([knn, reglog, lgbm, tree]):\n",
        "    scores.append(cross_val_score(model, Xtrain, Ytrain_classif, cv=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ropr5ra4z7pi"
      },
      "source": [
        "# On fait la moyenne des scores à chaque itération pour n'avoir qu'un seul\n",
        "# score par modèle \n",
        "scores_moy = [(model, np.mean(score)) for model, score in zip(\n",
        "    ['KNN', 'RegLog', 'LGBM', 'Tree'], scores)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae08KMGr59Zk"
      },
      "source": [
        "On affiche les résultats à l'aide d'un graphique "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMsLR9vmz70v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "c187150b-901d-42d8-fccc-0c1fb6b8dde6"
      },
      "source": [
        "# On augmente la taille de la figure\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# On y ajoute un titre\n",
        "plt.suptitle('Taux moyen de prédiction issus de la validation croisée pour chaque méthode', fontsize=16, color='red')\n",
        "\n",
        "# On affiche le diagramme en barres\n",
        "plt.bar(range(4),  np.array(np.array(scores_moy)[:,1], dtype=float), align='center', alpha=0.5)\n",
        "\n",
        "# On ajoute un titre à chaque barre afin de connaitre à quelle méthode elle corrrespond\n",
        "plt.xticks(range(4), np.array(scores_moy)[:,0])\n",
        "\n",
        "# On ajoute un titre à chaque axe\n",
        "plt.xlabel(\"Modèles\")\n",
        "plt.ylabel(\"Taux de prédiction\")\n",
        "\n",
        "# On affiche la figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w60n9kW6Tpt"
      },
      "source": [
        "Le meilleur modèle est donc clairement le LGBMClassifieur. C'est un avantage car c'est l'un des plus rapides. \n",
        "\n",
        "Par ailleurs, le taux de prédiction peut sembler assez faible (un peu moins de 75%) mais il ne faut pas oublier que la différence entre le cluster 0 et le cluster 1 est très faible pour les scores proches de 1 (0, 2, 3). En effet, il n'est pas illogique que le classifieur se \"trompe\" en classant un commentaire avec un score de 2 dans le cluster 1 ou lieu du cluster 0. Cela reste des erreurs \"faibles\" comparés au fait qu'il classe un commentaire avec un score de 500 dans le cluster 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxwP-ed96k6g"
      },
      "source": [
        "### 1-3 Application de la classification sur l'échantillon de test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUmLcnbwz8Dz"
      },
      "source": [
        "# Définition du meilleur modèle\n",
        "lgbm = LGBMClassifier(random_state=123)\n",
        "\n",
        "# Apprentissage (sur Ytrain_classif)\n",
        "lgbm.fit(Xtrain, Ytrain_classif)\n",
        "\n",
        "# Prédiction (sur Xtest)\n",
        "pred_classif = lgbm.predict(Xtest)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8YzP_gt7OLj"
      },
      "source": [
        "On doit également appliquer cette classification sur l'échantillon d'entrainement (par validation croisée) car pour entrainer le futur modèle de régression sur le groupe 0 (constitué normalement des commentaires ayant un score différent de 1), on doit utiliser un ensemble d'apprentissage plutôt \"similaire\" : celui qui aura était classé à 0 par validation croisée. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5sJpR4n6e-g"
      },
      "source": [
        "# Contrairement à la validation croisée précédente, ici le résultat est la \n",
        "# prédiction et non pas le taux de prédiction. \n",
        "pred_classif_train = cross_val_predict(lgbm, Xtrain, Ytrain_classif, cv=3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NXiAct38bz4"
      },
      "source": [
        "On ajoute les résultats de classification (aussi bien sur Train que sur Test) au DataFrame afin de séparer les échantillons d'apprentissage et de test en deux (un pour le cluster 0 un autre pour le cluster 1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lb1OKPe6fRB",
        "outputId": "355167a5-1a32-4b91-d6d9-c9525cc20e57"
      },
      "source": [
        "# On concatène les deux listes de résultats de clusters \n",
        "clusters = list(pred_classif_train) \n",
        "clusters.extend(pred_classif)\n",
        "\n",
        "# On vérifie que la longueur est bien égale au nombre de commentaires au total\n",
        "len(clusters)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4234970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dXfkLNh6fc7"
      },
      "source": [
        "# On l'ajoute dans une nouvelle colonne du DataFrame\n",
        "df['cluster'] = clusters"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3xMysSJ9ZIJ",
        "outputId": "7cbce212-4408-4824-981b-ded6a245079c"
      },
      "source": [
        "index_train_0 = [str(i) for i in df.loc[np.isnan(df['ups']) == False].loc[df['cluster'] == 0].index]\n",
        "index_train_1 = [str(i) for i in df.loc[np.isnan(df['ups']) == False].loc[df['cluster'] == 1].index]\n",
        "index_test_0 = [str(i) for i in df.loc[np.isnan(df['ups'])].loc[df['cluster'] == 0].index]\n",
        "index_test_1 = [str(i) for i in df.loc[np.isnan(df['ups'])].loc[df['cluster'] == 1].index]\n",
        "\n",
        "# Vérification \n",
        "len(index_train_0) + len(index_train_1) + len(index_test_0) + len(index_test_1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4234970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1YVsnrqJ4m7"
      },
      "source": [
        "Malgré le fait que le clustering n'est pas parfait, une grande majorité des commentaires de l'échantillon 'test' classés dans le groupe \"1\" sont censés avoir un score de \"1\" (ou très proche 0, 2). Ainsi au lieu d'appliquer un modèle de régression sur ce groupe de commentaire, on met pour chacun d'eux la prédiction à 1. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F90Yf2h89aSD"
      },
      "source": [
        "# On crée un dictionnaire qui met en relation l'index du commentaire et son score.\n",
        "# Ici le score est 1. Le dictionnaire sera mis à jour au fur et à mesure qu'on \n",
        "# prédit de nouveau score.\n",
        "prediction = dict([(index, 1)  for index in index_test_1])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw2kEyVgNI8I"
      },
      "source": [
        "Désormais, nous devons prédire les scores sur l'échantillon de test classé dans le cluster 0 (à partir de données d'entrainement classées également dans le clsuter 0). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io8NfkHYpxzE",
        "outputId": "46271407-ac5f-4c1e-a92b-9bed4a7b8301"
      },
      "source": [
        "Ytrain.loc[index_train_0].value_counts()[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    349091\n",
              " 2    285728\n",
              " 3    157997\n",
              " 0     69727\n",
              " 4     62719\n",
              " 5     57436\n",
              " 6     43039\n",
              " 7     31438\n",
              " 8     24122\n",
              "-1     23690\n",
              "Name: ups, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70AzZw0HOTSm"
      },
      "source": [
        "On s'aperçoit que malgré notre 1ère étape de classification, le nombre de commentaires ayant un score de \"1\" est encore majoritaire (bien qu'ils soient bien moins présents). <br> \n",
        "Nous avons fait le choix d'effectuer une deuxième étape de classification, cette fois-ci un peu plus large puisque nous souhaitons classe dans le cluster 2 les commentaires classés dans le cluster 0 lors de la première classification et qui ont un score de 1, 2 ou 3 (les scores ayant la plus forte proportion selon la liste précédente). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEuEaK1WWWr6"
      },
      "source": [
        "### 1-4 2e classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwWkgdfp75_b"
      },
      "source": [
        "def partition2(y):\n",
        "    \"\"\"\n",
        "    Fonction qui permet de transformer Ytrain (variable continue) en variable \n",
        "    binaire composée de 0 ou de 2. \n",
        "\n",
        "    Paramètre : \n",
        "        - y (int) : score du commentaire initial.\n",
        "    \n",
        "    Sortie : \n",
        "        - y (int) : deux valeurs possibles : 2 si le paramètre d'entrée \n",
        "        vaut 1, 2 ou 3, 0 sinon. \n",
        "    \"\"\"\n",
        "\n",
        "    if (y == 1 or y == 2 or y == 3):\n",
        "        y = 2\n",
        "\n",
        "    else :\n",
        "        y = 0\n",
        "\n",
        "    return y"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23emoApn8Jzf"
      },
      "source": [
        "Ytrain_classif_2 = [partition2(y) for y in Ytrain.loc[index_train_0]]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDENZkg08QAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5dadd1-8f58-4b6e-cddd-825989db8ae2"
      },
      "source": [
        "pd.Series(Ytrain_classif_2).value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    792816\n",
              "0    603221\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDNQtbPUQsBn"
      },
      "source": [
        "De nouveau, la classification devrait permettre d'obtenir deux groupes de taille plutôt équivalente. \n",
        "\n",
        "Appliquons à nouveau le modèle de classification. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZiDA1gMjDs_"
      },
      "source": [
        "# Définition du meilleur modèle\n",
        "lgbm = LGBMClassifier(random_state=123)\n",
        "\n",
        "# Apprentissage (sur Ytrain_classif_2)\n",
        "lgbm.fit(Xtrain.loc[index_train_0], Ytrain_classif_2)\n",
        "\n",
        "# Prédiction (sur Xtest classé comme 0 à la première classification)\n",
        "pred_classif_2 = lgbm.predict(Xtest.loc[index_test_0])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctIXBCZBRY9D"
      },
      "source": [
        "On doit toujours appliquer cette classification sur l'échantillon d'entrainement (par validation croisée).En effet, pour entrainer le futur modèle de régression sur le groupe 0 (constitué normalement des commentaires ayant un score différent de 1, 2 ou 3), on doit utiliser un ensemble d'apprentissage plutôt \"similaire\" : celui qui aura était classé à 0 lors de la  validation croisée. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZcasJPMsUG7"
      },
      "source": [
        "pred_classif_train_2 = cross_val_predict(lgbm, Xtrain.loc[index_train_0], Ytrain_classif_2, cv=3)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmWqKw3_Tatw"
      },
      "source": [
        "On met à jour le numéro de clusters (certains commentaires classés 0 lors de la 1zere classification sont désormais classés 2). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxQseZefhWhh"
      },
      "source": [
        "df.loc[index_train_0, ['cluster']] = pred_classif_train_2\n",
        "df.loc[index_test_0, ['cluster']] = pred_classif_2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TevOEonT-77"
      },
      "source": [
        "On récupère les nouveaux indexes des clusters 0 et 2 (ceux du cluster 1 restent inchangés)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf7I5mUCNp9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acddbf5e-4821-451b-afe8-c1e3dafc7536"
      },
      "source": [
        "# Mise à jour des indexes \n",
        "index_train_0 = [str(i) for i in df.loc[np.isnan(df['ups']) == False].loc[df['cluster'] == 0].index]\n",
        "index_train_2 = [str(i) for i in df.loc[np.isnan(df['ups']) == False].loc[df['cluster'] == 2].index]\n",
        "\n",
        "index_test_0 = [str(i) for i in df.loc[np.isnan(df['ups'])].loc[df['cluster'] == 0].index]\n",
        "index_test_2 = [str(i) for i in df.loc[np.isnan(df['ups'])].loc[df['cluster'] == 2].index]\n",
        "\n",
        "# Vérification \n",
        "len(index_train_0) + len(index_train_1) + len(index_test_0) + len(index_test_1) + \\\n",
        "len(index_train_2) + len(index_test_2)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4234970"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wbp9AghUkBl"
      },
      "source": [
        "Mettons à jour le dictionnaire de nos prédictions.\n",
        "\n",
        " Le groupe 2 est censé contenir une grande majorité de commentaires devant avoir un score de 1, 2 ou 3. Comme précédement, nous jugeons qu'il est plus pertinent de donner à l'ensemble de ces commenataires une seule et même valeur plutôt que d'essayer d'y entrainer un modèle de régression (les résultats des soumissions nous donne raison). \n",
        "\n",
        " Cependant, cette fois-ci, le choix de la valeur est un peu moins évidente que le 1 précédent. Nous avons fait le choix de donner la valeur \"2\" qui est un bon compromis entre 1 et 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwAAFUNxNqtI"
      },
      "source": [
        "# On ajoute de nouvelles prédictions \n",
        "prediction.update(dict([(index, 2)  for index in index_test_2]))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl-yOnUnVwXo"
      },
      "source": [
        "Nous pouvons enfin passer à l'apprentissage d'un modèle de régression sur les données du cluster 0. Ce cluster étant beaucoup plus hétérogène qu'initialement, nous estimons que le modèle de régession aura plus de faciliter à prédire (il ne sera plus gêné par l'abondance de \"1\"). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwOfPtcdWFAF"
      },
      "source": [
        "## (2) Modèle de régression\n",
        "Pour ce modèle de régression nous partons directement sur le modèle LightGBM car c'est l'un des modèles les plus performants (voire le plus performant) dans les compétitions Kaggle. De plus, en faisant des validations croisées sur l'échantillon d'apprentissage c'est lui qui nous offrait les meilleurs performances par rapport aux autres modèles, notamment XGBoost.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw8N2DPCcJk8"
      },
      "source": [
        "# On ne doit plus que prédire les scores du clusters 0, d'où :\n",
        "Xtrain0 = Xtrain.loc[index_train_0]\n",
        "Ytrain0 = Ytrain.loc[index_train_0]\n",
        "Xtest0 =  Xtest.loc[index_test_0]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hl1FqP5ch4x"
      },
      "source": [
        "### 2-1 Sélection des features les plus pertinentes\n",
        "L'amélioration de ce modèle peut être fait de deux façons : le tuning des hyperparamètres (c'est-à-dire l'opitmisation des paramètres du modèle) ou la sélection de features. <br> \n",
        "Nous commençons ici par la sélection de features. Nous entrainons un modèle sur l'échantillon de train0 et on regarde quelles sont les features les plus importantes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm75P_nNNq5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfde1f35-a7b1-4a28-9aa7-09c46f34b454"
      },
      "source": [
        "# On réalise un premier apprentissage pour déterminer les features avec la plus\n",
        "# grande importance\n",
        "LGBM = LGBMRegressor(random_state=12345)\n",
        "LGBM.fit(Xtrain0, Ytrain0)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=12345, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "2fTC5xs8d7Ru",
        "outputId": "9ec2fb80-80eb-4c9d-b982-88ba99ee3e54"
      },
      "source": [
        "# Taille de la figure \n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "# Importance des features\n",
        "importance = np.abs(LGBM.feature_importances_)\n",
        "\n",
        "# Noms des features (ici comme il y en a beaucoup on les numérote seulement)\n",
        "feature_names = np.array(range(0,34))\n",
        "\n",
        "# Histogramme\n",
        "plt.bar(height=importance, x=feature_names)\n",
        "\n",
        "# Titre\n",
        "plt.title(\"Importance des features pour le modèle de régression LGBM\")\n",
        "\n",
        "# Affichage\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwaHpiWieOFe"
      },
      "source": [
        "On voit clairement à l'aide de ce graphique qu'il y a des features qui aident à la prédiction (17, 22, etc). Et d'autres pas du tout (4, 34, 35). On ne sait pas à quoi elles correspondent, donc faisons la correspondance entre les numéros et leur nom. \n",
        "\n",
        "On récupère les 17 features qui ont un coefficient supérieur à 50. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31OkLyhpepCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "041ea29b-c9a0-405b-aa0d-73288aeba638"
      },
      "source": [
        "indexes_best_features = np.argsort(importance)[::-1][:17]\n",
        "[(features, index) for index, features in enumerate(Xtest.columns) if index in indexes_best_features]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('length_comment_chars_before_NLP', 4),\n",
              " ('length_comment_chars_after_NLP', 5),\n",
              " ('sentiment_child', 8),\n",
              " ('nb_direct_resp', 10),\n",
              " ('nb_total_resp', 11),\n",
              " ('author_centrality_degree', 12),\n",
              " ('author_centrality_ev', 13),\n",
              " ('author_prestige_degree', 14),\n",
              " ('resp_time_parent', 15),\n",
              " ('resp_time_topic', 16),\n",
              " ('score_parent', 17),\n",
              " ('score_topic', 18),\n",
              " ('nb_comments_parent', 19),\n",
              " ('nb_comments_topic', 20),\n",
              " ('ratio_topic', 21),\n",
              " ('author_mean_score', 22),\n",
              " ('comment_karma', 26)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyXfRr5ZeiBU"
      },
      "source": [
        "Voici la liste des features ayant le plus grand impact sur la régression. Sans surprise on retrouve les features liées au score des éléments autour du commentaire (score du parent, score du topic, score moyen de l'auteur, etc). \n",
        "\n",
        "On a \"joué\" avec cette liste pour obtenir les meilleures prédictions sur l'échantillon de test. Finalement, le nombre de features retenues est de 12. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etXsuoT_NrGN"
      },
      "source": [
        "# Modification des échantillons d'apprentissage et de test \n",
        "indexes_best_features = [4, 5, 8, 10, 11, 15, 16, 18, 19, 20, 22, 26]\n",
        "\n",
        "Xtest0 = Xtest0.iloc[:, indexes_best_features]\n",
        "Xtrain0 = Xtrain0.iloc[:, indexes_best_features]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHa3SpxhWhn"
      },
      "source": [
        "# Apprentissage avec un nombre de features réduit\n",
        "LGBM = LGBMRegressor(random_state=12345)\n",
        "LGBM.fit(Xtrain0, Ytrain0)\n",
        "pred = LGBM.predict(Xtest0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS4uW8RHiI0t"
      },
      "source": [
        "# Ajout des dernières prédictions\n",
        "# Le score que l'on prédit doit être un entier donc il faut \"caster\" la prédiction\n",
        "prediction.update(dict([(index, int(predic))\n",
        "                        for index, predic in zip(index_test_0, pred)]))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6hX0V5vgtHW"
      },
      "source": [
        "Après soumission, on constate une amélioration des résultats. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aYrr7Z51Rku"
      },
      "source": [
        "### 2-2 Optimisation des hyper-paramètres\n",
        "Tous les algorithmes d'apprentissage sont paramétrables. Les valeurs de ces paramètres peuvent impacter les performances du modèle et sont dépendantes des données manipulées. Il peut alors être intéressant de chercher les meilleures valeurs de ces paramètres pour booster la performance de notre modèle. C'est ce que l'on appelle l'étape d'optimisation des hyper-paramètres. <br> \n",
        "Normalement la stratégie à adopter est l'utilisation d'une grille de recherche telle que : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu8JXooxYg-q"
      },
      "source": [
        "# On définit des listes de valeurs pour certains paramètres. \n",
        "parameters_LGBM = { \n",
        "    'num_leaves': np.arange(5, 100, 5),\n",
        "    'n_estimators ' : np.arange(100, 1000, 100), \n",
        "    'subsample_for_bin ' : np.arange(50000, 500000, 50000), \n",
        "    'objective ' : ['regression'], \n",
        "    'min_child_samples ' : np.arange(10, 500, 50), \n",
        "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
        "    'importance_type ' : ('split', 'gain'),\n",
        "    'learning_rate' : [0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
        "}"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utv8w7tjYg-q",
        "outputId": "26d70563-e055-4cd6-e9f4-ea921fb5eae0"
      },
      "source": [
        "# Nombre de combinaison \n",
        "len(list(ParameterGrid(parameters_LGBM)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1662120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD5omrvG2amA"
      },
      "source": [
        "Comme le nombre de paramètres à optimiser est important, le nombre de combinaisons possibles explose. Il est bien évidemment impossible de tester chacune des solutions. La solution est de passer par la fonction `RandomizedSearchCV` qui permet de texter aléatoirement `n_iter` combinaison. <br> \n",
        "Le problème est que pour tester au moins 10% des solutions possibles, il faudrait tester plus de 150 000 combinaisons et donc entrainer 150 000 fois le modèle. Ce qui serait très très long. <br> \n",
        "Nous avons effectué seulement 1000 entrainement, mais le résultat retrouné n'améliorait pas notre modèle (ce qui n'est pas étonant car il aurait fallut beaucoup de chance pour donner sur la bonne combinaison sachant qu'on en tire aléatoirement 1000 parmi 1.6 millions...). C'est une méthode que nous avons donc abandonné. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_L-U7_sYg-r"
      },
      "source": [
        "classifier = LGBMRegressor(random_state=123, silent=True, metric='l1', n_jobs=-1)\n",
        "\n",
        "find_parameters = RandomizedSearchCV(\n",
        "    estimator=classifier, param_distributions=parameters_LGBM, \n",
        "    n_iter=1000,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    cv=3,\n",
        "    random_state=300,\n",
        "    verbose=False)\n",
        "\n",
        "# Prend plus d'une heure à être exécuté\n",
        "#find_parameters.fit(Xtrain0, Ytrain0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k02ZWx-NYg-s"
      },
      "source": [
        "print('Best score : {} with parameters: {} '.format(find_parameters.best_score_, find_parameters.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoEofxIA35Vj"
      },
      "source": [
        "Pour optimiser les paramètres de notre modèle `LGBMRegressor`, nous avons donc dû procédé manuellement. Pour cela, la [page officiel du LGBM](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html) nous a été d'une aide précieuse. En effet, on y apprant que pour un meilleur score, il est conseillé soit d'augmenter la valeur de `max_bin` (ce qui peut ralentir l'entrainement), soit de diminuer la valeur de `learning_rate` et augmenter celle de `n_estimators`, soit d'augmenter la valeur de `large num_leaves` ou soit d'utiliser le boosting de type `dart` au lieu de `gbdt`. <br> \n",
        "Après plusieurs tests, nous avons finalement diminué la valeur de `learning_rate` et augmenté celle de `n_estimators` (nombre d'itérations). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZSgVvDs0lZa"
      },
      "source": [
        "LGBM = LGBMRegressor(random_state=12345, learning_rate=0.01, n_estimators=500)\n",
        "LGBM.fit(Xtrain0, Ytrain0)\n",
        "pred = LGBM.predict(Xtest0)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3EoWpFH5xwX"
      },
      "source": [
        "On peut mettre à jour les prédictions sur le cluster 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOjOq2Ar5irS"
      },
      "source": [
        "# Mise à jour des dernières prédictions (elles seront remplacées pas dupliquées)\n",
        "# Le score que l'on prédit doit être un entier donc il faut \"caster\" la prédiction\n",
        "prediction.update(dict([(index, int(predic))\n",
        "                        for index, predic in zip(index_test_0, pred)]))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjSQo1MF6Fiy",
        "outputId": "829a8ff7-e581-42e8-a9e6-86e44b95642b"
      },
      "source": [
        "len(prediction)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1016458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdg5G625-rK"
      },
      "source": [
        "### 2-3 Sousmission \n",
        "Nous avons prédit l'ensemble des commentaires de l'échantillon de test. On peut désormais regrouper le tout dans un DataFrame que nous stockerons dans un fichier qui servira de sousmission sur le site de Kaggle. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ESU13GYgKu"
      },
      "source": [
        "# Identifiants des commentaires\n",
        "name_submission = [n[3:] for n in name[3218512:]]\n",
        "# Prédictions des scores\n",
        "pred_submission = [prediction[index] for index in df_test.index]\n",
        "\n",
        "# DataFrame\n",
        "df_submission = pd.DataFrame({'id' : name_submission, \n",
        "                              'predicted' : pred_submission})\n",
        "\n",
        "# Enregistrement dans un fichier \n",
        "df_submission.to_csv(pathFile + 'submission_kaggle.csv', index=False)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DZ39X_L7em0"
      },
      "source": [
        "# Bilan \n",
        "Même si le score nous semble être en deçà de notre travail effectué tout au long de ce projet, nous estimons que nous avons fait de notre mieux dans la recherche de features et surtout sur la recherche d'informations supplémentaires sur les auteurs et les topics/posts (par scraping) <br> \n",
        "La partie sur l'analyse du contenu des commentaires aurait toutefois méritée plus de travail, mais limités par le temps, nous n'avons pu effectuer tout ce que nous voulions mettre en place (LDA, similirité entre commentaire et le sujet). Peut-être c'est ce qu'il nous a manqué pour amélioré notre score. \n"
      ]
    }
  ]
}