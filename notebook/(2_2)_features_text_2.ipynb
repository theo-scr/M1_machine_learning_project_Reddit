{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(2-2)_features_text_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EwEfNnm9jPv"
      },
      "source": [
        "<strong>Date :</strong> Créé le 03 Avril 2021| Mis à jour le 11 Avril 2021 </strong>\n",
        "\n",
        "<strong>Compétition Kaggle - Team Théo\n",
        "    \n",
        "@auteur : </strong>Théo SACCAREAU & Théo VEDIS\n",
        "\n",
        "<strong>(2-2)_features_text_2\n",
        "      \n",
        "Description :</strong> A travers ce Notebook, nous poursuivrons l'analyse du contenu et l'extraction de features textuelles en réalisant une analyse topicale.\n",
        "\n",
        "\n",
        "Temps d'exécution du Notebook : environ  1h30."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbY_2IWqE79y"
      },
      "source": [
        "<strong> (!) L'exécution de ce Notebook est FACULTATIVE.(!) </strong>Aucune feature n'y sera générée, vous pouvez directement passer au Notebook (2-3)_features_network_1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imAEsGzZGyz-"
      },
      "source": [
        "# Installer / Télécharger / Importer des librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcvnUgP4Gyz4"
      },
      "source": [
        "# Librairies usuelles\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "\n",
        "# Librairie pour le texte\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel, CoherenceModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUNxsXdGMpP"
      },
      "source": [
        "# Chemin "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY896iIwGy0G"
      },
      "source": [
        "# Chemin relatif vers le dossier \"data\" (inutile de le changer).\n",
        "pathFile = \"../data/\" "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaPBGrY2AciM"
      },
      "source": [
        "# Chargement des données d'entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAwAmPvxAI3w"
      },
      "source": [
        "# Chargement du fichier .csv contenant les contenus textuels nettoyés.\n",
        "# Temps exécution : environ 40s\n",
        "data_LDA = pd.read_csv(pathFile + \"data_LDA.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB11_D8n9ASg"
      },
      "source": [
        "# On remplace les valeurs nulles par des chaînes vides. \n",
        "data_LDA = data_LDA['bodyNLP2'].fillna('')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09fMtpuop09o"
      },
      "source": [
        "# (3) Analyse topicale\n",
        "L'objectif ici est de réaliser une fouille thématique non surpervisée, c'est-à-dire trouver les sujets / les thèmes évoqués dans une collection de texte. On va donc réaliser du clustering en regroupant dans des groupes des documents (ici les commentaires/posts) similaires. \n",
        "\n",
        "Plusieurs modèles sont possibles (kmeans, LSA, PLSA, NMF, etc), nous avons fait le choix d'utiliser le modèle LDA : Allocation Dirichlet Latente. C'est le modèle qui offre les meilleurs résultats et le plus utilisé. \n",
        "\n",
        "Sans revenir sur tout ce qui a été vu en cours, ce modèle essaie de modéliser comment une personne écrit un document : elle choisit un topic puis elle sélectionne des mots à l'intérieur de ce topic. La notion de distribution est donc au centre de ce modèle : la distribution de mots dans chaque thématique, dans chaque document, etc. Dernier point, en entré ce modèle prend uniquement une matrice de fréquence (pas de TF-IDF). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbCBi0Vahs5I"
      },
      "source": [
        "# On récupère les informations scrapées sur les topics.\n",
        "# Temps exécution : 40s\n",
        "df2 = pd.read_json(pathFile + \"data_post.json\").T \n",
        "topics = df2['title'] "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br-IGTyeIFYL"
      },
      "source": [
        "On applique au contenu des posts le même prétraitement que celui appliqué aux contenus des commentaires (tokenisation, suppression des stopwords et lemmatisation). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roQqozfFiR9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b34b88d-7e8a-4b83-e2a6-b21b16ecd61f"
      },
      "source": [
        "# (1) Tokenisation \n",
        "# On ne prend en compte que les caractères alpha-numérique, la ponctuation\n",
        "# est donc exclue.\n",
        "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# (2) Suppression des mots vides\n",
        "stop_words = set(tuple(nltk.corpus.stopwords.words('english')))\n",
        "topics = topics.apply(lambda x : \" \".join([i for i in tokenizer.tokenize(x.lower()) if not i in stop_words and len(i) >= 4]))\n",
        "\n",
        "# (3) Lemmatisation \n",
        "wnl = WordNetLemmatizer()\n",
        "topics = [\" \".join([wnl.lemmatize(words) for words in tokenizer.tokenize(x)]) for x in tqdm(topics)]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 148848/148848 [00:04<00:00, 31907.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OllOC14pboDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace38ce9-f7f3-4851-ba92-c97f6de31200"
      },
      "source": [
        "# On concatène la liste des contenus des commentaires à la liste des \n",
        "# contenus des posts.  \n",
        "texts = [tokenizer.tokenize(comment) for comment in tqdm(data_LDA)]\n",
        "texts.extend( [tokenizer.tokenize(topic) for topic in tqdm(topics)])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4234970/4234970 [00:21<00:00, 198765.02it/s]\n",
            "100%|██████████| 148848/148848 [00:00<00:00, 413728.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKlCBi3LIzha"
      },
      "source": [
        "On prépare les données que nous donnerons au modèle LDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKVyrlchcR7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae2bdab-30f4-4fa4-cc89-4ba8609de8d0"
      },
      "source": [
        "# Créer le dictionnaire qui associe un identifiant à chaque mot \n",
        "# Temps exécution : environ 2 min\n",
        "id2word  = corpora.Dictionary(texts)\n",
        "\n",
        "# Créer le corpus\n",
        "corpus = [id2word.doc2bow(text) for text in tqdm(texts)]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4383818/4383818 [00:54<00:00, 81110.11it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwExvdrBI-v6"
      },
      "source": [
        "On met en place le modèle LDA. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zui3V-d-VlQz"
      },
      "source": [
        "# Construire le modèle LDA\n",
        "\n",
        "# Choix du nombre de topic totalement arbitraire (cf ci-dessous)\n",
        "num_topic = 20 \n",
        "\n",
        "# Temps exécution : 50 min. \n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
        "                                            id2word=id2word, \n",
        "                                            num_topics=num_topic, \n",
        "                                            chunksize=len(corpus), \n",
        "                                            update_every = 1, \n",
        "                                            random_state=1,\n",
        "                                            alpha='auto')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n8FZhxMJLPY"
      },
      "source": [
        "Observons le résultat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "een4kIliVnpb",
        "outputId": "93050a4e-2f12-4325-94ba-9976d305a087"
      },
      "source": [
        "# Affichage des mots les plus probables pour chaque topic\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '0.018*\"people\" + 0.011*\"think\" + 0.007*\"time\" + 0.007*\"like\" + 0.007*\"know\"')\n",
            "(1, '0.013*\"people\" + 0.009*\"time\" + 0.009*\"would\" + 0.009*\"know\" + 0.008*\"much\"')\n",
            "(2, '0.015*\"like\" + 0.010*\"really\" + 0.008*\"good\" + 0.006*\"never\" + 0.006*\"people\"')\n",
            "(3, '0.013*\"time\" + 0.013*\"would\" + 0.012*\"like\" + 0.010*\"year\" + 0.007*\"people\"')\n",
            "(4, '0.017*\"know\" + 0.012*\"people\" + 0.007*\"make\" + 0.007*\"like\" + 0.007*\"back\"')\n",
            "(5, '0.018*\"like\" + 0.010*\"people\" + 0.009*\"thing\" + 0.008*\"would\" + 0.008*\"make\"')\n",
            "(6, '0.015*\"like\" + 0.012*\"people\" + 0.009*\"year\" + 0.006*\"feel\" + 0.006*\"thing\"')\n",
            "(7, '0.022*\"like\" + 0.009*\"would\" + 0.007*\"please\" + 0.007*\"time\" + 0.007*\"thing\"')\n",
            "(8, '0.009*\"people\" + 0.009*\"would\" + 0.008*\"like\" + 0.007*\"make\" + 0.005*\"shit\"')\n",
            "(9, '0.012*\"like\" + 0.010*\"time\" + 0.009*\"would\" + 0.008*\"want\" + 0.007*\"think\"')\n",
            "(10, '0.016*\"like\" + 0.013*\"people\" + 0.012*\"would\" + 0.009*\"time\" + 0.005*\"even\"')\n",
            "(11, '0.010*\"like\" + 0.008*\"think\" + 0.007*\"thing\" + 0.006*\"shit\" + 0.006*\"could\"')\n",
            "(12, '0.019*\"would\" + 0.016*\"like\" + 0.014*\"think\" + 0.009*\"time\" + 0.009*\"people\"')\n",
            "(13, '0.012*\"like\" + 0.008*\"know\" + 0.008*\"people\" + 0.007*\"thing\" + 0.006*\"life\"')\n",
            "(14, '0.010*\"like\" + 0.008*\"people\" + 0.007*\"time\" + 0.006*\"would\" + 0.006*\"good\"')\n",
            "(15, '0.022*\"please\" + 0.020*\"question\" + 0.018*\"post\" + 0.017*\"reddit\" + 0.014*\"askreddit\"')\n",
            "(16, '0.008*\"like\" + 0.008*\"year\" + 0.008*\"thing\" + 0.007*\"really\" + 0.007*\"well\"')\n",
            "(17, '0.010*\"people\" + 0.010*\"need\" + 0.009*\"please\" + 0.008*\"question\" + 0.007*\"comment\"')\n",
            "(18, '0.012*\"would\" + 0.007*\"like\" + 0.007*\"time\" + 0.006*\"know\" + 0.006*\"love\"')\n",
            "(19, '0.011*\"really\" + 0.010*\"time\" + 0.008*\"thing\" + 0.007*\"make\" + 0.007*\"http\"')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SogmUHNSkrqG"
      },
      "source": [
        "A la vue des résultats, le modèle de LDA donne clairement des résultats pas satisfaisants. Plusieurs éléments peuvent expliquer cela. \n",
        "\n",
        "Tout d'abord le choix du nombre de topic, nous avons pris 20 purement arbitrairement. Mais avec plus de 150 000 links/posts et 4 millions de commentaires, on aurait dû sûrement augmenter cette valeur. Le problème c'est qu'au delà (50 par exemple), la RAM ne suportait pas. Normalement, pour choisir le nombre de cluster optimal, nous devrions effectuer plusieurs fois le LDA pour des valeurs de k différentes et comparer les résultats des métriques (perplexity ou coherence). Cependant, avec plus de 50 min pour entrainer un seul modèle, nous sommes limités par le temps. \n",
        "\n",
        "Ensuite, les paramètres du modèle peuvent avoir jouer un rôle. Par exemple, nous avons laissé la valeur par défaut 1 pour le paramètre `passes` (nombre de passages dans le corpus pendant la formation), or beaucoup de sources indiquent que ce paramètre doit être mis à 10 voire 20. Toujours limité par les temps de calcul, nous ne pouvions mettre une telle valeur. C'est ce qui peut expliquer les mauvais résultats. \n",
        "\n",
        "Enfin, dernière explication, peut-être que notre traitement de texte préalable n'était pas suffisant.\n",
        "\n",
        "Il ne semble clairement pas utile d'en déduire des features. Initialement, nous aurions aimé créé une feature renseignant le numéro de cluster pour chaque document et une autre feature renseignant si oui ou non le commentaire appartient au même cluster que son parent. \n",
        "\n",
        "Par manque de temps, nous n'avons pu tester d'autres modèles (NMF, Kmeans, PLSA, etc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Ipl6NVHUT_"
      },
      "source": [
        "Voici pour conclure les métriques permettant de mesure la qualité d'un modèle LDA. Tout seule elles n'ont pas vraiment d'intéret. Elles sont utiles lorsqu'on réalise plusieurs modèles avec des valeurs de k différentes. Effectivement, elles permettent de choisir la valeur de k optimum. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcUR1-I4cizv"
      },
      "source": [
        "# Afficher le \"Perplexity score\"\n",
        "# Temps d'exécution : 28 min \n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus)) # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Afficher le \"Coherence Score\"\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnhxqkGgzhck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}